\chapter{Conclusion}
\section{Critical Evaluation}

While an extensive review of the literature provided a great foundation for the work that was to be completed, it was the implementation of these techniques that solidified a greater understanding of neural machine translation and the project itself.
This was a very challenging project but ultimately the research objectives were met and a lot was learnt about the problems with low-resource machine translation and the techniques that can be applied to overcome these challenges. Although the outcome of the experiments was not what was originally anticipated, the findings are still insightful and may prove beneficial to future research surrounding low-resource \acrshort{NMT}.

Several setbacks arose throughout the implementation that caused significant delays in the project development and experimentation. While the implementation of the translation model originally seemed fairly straightforward, it became clear that the Sequential Keras API that had been used previously in initial testing would not support the more complex architectures proposed by the literature regarding current \acrshort{NMT} and transfer learning methods. The decision was made to switch to the Functional Keras API but it took multiple weeks before a working model was implemented and ready to train. In addition, the \acrshort{GRU} implementation used \cite{bahdanau_neural_2016} attention rather than the more commonly used \cite{luong_effective_2015} attention which has shown to be successful in the existing transfer learning literature. It is currently unclear how much of an impact these alterations may have impacted the results of the experiments but may be worth investigating in the future.

Once the models were implemented and had the supporting code required for the many intricacies of machine learning, it was discovered that the quality of the original data that was collected (mainly technical localisation files) was not sufficient for the low-resource \acrshort{NMT} that was planned. Therefore an entirely new data corpus was generated before any experiments were completed. Once the new data was finalised, it was discovered that the models could not use all of the available data due to limitations in the available hardware. Had more powerful GPU's been accessible, the translation models would include both more data and dimensionality in the model architecture. It is thought that in combination with a more representative, high-quality dataset this would significantly improve the translation quality of all experiment models. More investigation into the quantity of data and languages that this data can be effectively transferred to during transfer learning is required.

The vocabulary size and sentence length experiments carried out in Section \ref{sec:4-vocab_size} and \ref{sec:4-sentence_length} were both carried out solely on the baseline model and the results of these experiments were used to determine the parameters of subsequent experiments. While a vocabulary size of 5000 and sentence length of 15 may have been beneficial for the baseline model, the transfer learning models may have benefited from alternative parameters.

A limitation of the evaluation is that they are limited to a single reference sentence for each hypothesis (translation). Sentences can be phrased in a variety of ways while retaining the original meaning of the sentence, meaning that even if a sentence translation may be correct, should the phrasing or word choice be different, the translation score is negatively affected. Having multiple references for each hypothesis may significantly reduce the impact of this potential bias on the results.



\section{Future Work}

It was identified in the experiments regarding vocabulary size and sentence length that these parameters can significantly alter the quality of a translation. Further research into the upper and lower ranges of these parameters could be conducted using several and a variety of data categories (parliamentary, informal, etc.) to provide greater insight into the factors that may lead to these discrepancies.

Future work relating to the project may investigate the use of an \acrshort{LSTM} instead of a \acrshort{GRU} for the model architecture in a low-resource context. Similarly, the use of \cite{luong_effective_2015} attention would significantly change the architecture of the model which may lead to significant changes in experiment outcomes. The use of Luong attention also enables the "freezing" of word embeddings during transfer learning which means they are not updated during training. By keeping the word embeddings from the high-resource language, a better foundation in which the low-resource language translation builds upon may be provided and lead to an improvement in translation quality.

Finally, the implementation of the meta learning technique described in Section \ref{sec-2:meta_learning} has the potential to provide results that exceed the limitations of current trivial and hierarchical transfer learning implementation. It is therefore recommended that experimentation regarding the use of Scottish Gaelic in a meta learning translation system should be investigated further.

% Try more data with larger vocab sizes. Benchmark the model using standardised datasets from previous research papers and NMT competitions.


\section{Conclusion}

The project has identified limitations in the implementation of trivial transfer learning and hierarchical transfer learning in regards to the translation quality of a Scottish Gaelic \acrshort{NMT} system. While it was expected that due to the nature of being a low-resource language and having such a limited dataset that translations may not be in line with expectations of those familiar with existing translation tools such as Google Translate, the translations for all of the implemented models were still disappointing. The baseline model outperforming the transfer learning models was also unexpected but upon further inspection, it was found that despite receiving lower translation evaluation scores, both transfer learning methods often provided a more varied and representative translation in comparison to the baseline model which appeared to consistently output the same subset of translations using frequently occurring words. This highlighted some of the issues present with automatic translation evaluation techniques that simply rely on n-gram counts to determine the translation quality of an entire data corpus.

In conclusion, this project has been successful in regards to the investigation and implementation of low-resource neural machine translation, providing a greater understanding of the techniques and parameter tuning that can have a significant impact on the output quality of a translation model in a low-resource context. The choice of low-resource language has contributed research towards an area of machine translation that has no prior research papers relating to Scottish Gaelic \acrshort{NMT}.