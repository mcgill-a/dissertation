\chapter{Analysis and Discussion}

While it would have been insightful to include a baseline experiment with purely original Scottish Gaelic data, it was discovered during initial testing that the low quality and quantity of data did not produce any \acrshort{NMT} output whatsoever which resulted in consistent \acrshort{BLEU} scores of 0. As such, all experiments involving Scottish Gaelic data required the use of the additional back-translated data.

Given the hardware constraints of this project resulting in a limited dataset size, reduced vocabulary size and restricted model architecture, the models were observed to be overfitting before 20 epochs were completed. Dropout and recurrent dropout were implemented to reduce the rate of overfitting. While this did initially slow the rate of overfitting, the translation \acrshort{BLEU} scores were negatively impacted such that the additional training epochs were negligible. Had these constraints not been in place, the models would've been able to train for significantly more epochs given the increase in trainable parameters. Based on the literature identified in Section \ref{sec:2-transfer_learning}, it is expected that this would lead to an increase in translation quality across each experiment.

\section{Vocabulary Size}
The vocabulary size experiment in Section \ref{sec:4-vocab_size} revealed that a vocabulary size of 5000 lead to a significant increase in \acrshort{BLEU} score in comparison to 4000 and 7000. Through an analysis of the training and validation data, it was observed that out of an overall vocabulary size of around 12000, approximately 7000 words occurred at least 3 times. Therefore, a considerable percentage of the vocabulary in this sample size will only occur 3 times. As the vocabulary size reduces to 5000, the vocabulary prioritisation has naturally increased the minimum word occurrence to 5. Finally, as the vocabulary size reaches 4000, the minimum word occurrence is 8.

The results suggest that when too much of the vocabulary is replaced using unknown word replacement (2/3 of the unique words in the case of a vocabulary size of 4000), translation quality suffers significantly. This can be explained by the way in which automatic translation evaluations such as \acrshort{BLEU} score are calculated. If the words from the reference sentence are outwith the vocabulary of the output translation then it will receive a lower \acrshort{BLEU} score because of a reduction in n-gram count occurrences. However, the results also show that increasing the vocabulary size too much can also lead to a reduction in \acrshort{BLEU} score. Due to the low frequency of occurrences in the data, it is thought that the additional words and a lack of example sentences using these words add noise to the network, making it more difficult to predict the correct output sentence. Therefore, the vocabulary size of the model architecture should be dependent on the data corpus being used in that specific case, rather than a predetermined general value that works well for a multitude of datasets. In this case, it was found that out of a total vocabulary size of approximately 12000, a vocabulary size of 5000 resulted in the best translation quality.

\section{Sentence Length}

During experimentation regarding the sentence length in Section \ref{sec:4-sentence_length}, it was discovered that lower validation loss during training does not necessarily lead to improvements in translation quality. Throughout the entire duration of the training, the sentence length of 20 consistently resulted in a lower validation loss. However, evaluating the models using a \acrshort{BLEU} score evaluation showed that having a sentence length of 15 resulted in improved translation quality. It is thought that the improvement in \acrshort{BLEU} score seen with a 15-word limit is primarily due to a reduction in the padding required to standardise the length of all the variable-length sentences.

As identified in the analysis of the data in \ref{fig:sentence_length-gaelic}, approximately 96\% of sentences in the Scottish Gaelic data corpus contains 15 words or less, with a significant proportion of those sentences at 10 words or less. This will likely be an additional factor that has had an impact on the results of the experiment. Given that there are more samples of shorter sentences, it can be expected that the network will favour the translation of shorter sentences in terms of translation quality. Finally, it is thought that as the size of the sentence increases, so does the probability that the sentence will include a less frequently occurring word. Not only increasingly difficult for the network to predict less frequently occurring words, but it may also be the case that the word is out of the vocabulary. In which case, even upon the correct prediction of the unknown word token in its place, the reference sentence will contain the actual word and as such the \acrshort{BLEU} score will be negatively affected.

\section{Low Resource Approaches}

The results of the baseline model, trivial transfer learning, and hierarchical transfer learning experiments are collated in Figure \ref{fig:bleu_results}, and Table \ref{tab:bleu_table}. Using both \acrshort{BLEU} and \acrshort{NIST} translation evaluation metrics, it appears that the baseline model significantly outperforms both of the transfer models by up to as much as 0.09 \acrshort{BLEU} score. However, a closer look into the sentences that are output by the translation models reveals some interesting findings. The sentence analysis table that is shown in Table \ref{tab:sentence_analysis} includes two sample sentences directly from the test set that is exemplary of the kind of quality to be expected by each of the models. While the quality of all the translations is very poor, it is has been observed that there are some clear patterns in the data for all of the models. For example, the baseline model appears to consistently output phrases such as ``the unk is the unk" (with ``unk" being the unknown word token). While this translation may typically be no less related to the reference translation than the transfer learning methods, the inclusion of commonly occurring words increases the likelihood of achieving a higher \acrshort{BLEU} score which may introduce bias into any automatic translation evaluation. In contrast, the sentences from the transfer learning models are much more varied and have clearly been influenced by their parent models. Despite this influence, it appears that the random mapping of word embeddings that took place during the replacement of the datasets and subsequent training on this initialisation has not been substantial enough to result in usable translations. 


% Negative transfer
The trivial transfer learning experiment in Section \ref{sec:4-trivial}, showed that the trivial model consistently achieved \acrshort{BLEU} scores worse than the baseline model which had no transfer learning. This was an unexpected result given the findings of the trivial transfer learning research described in \ref{sec:2-transfer_learning}.  
However, \cite{wang_negative_transfer_2019} found that the relatedness of the language pair may be less important than the quantity of the training data. It has been observed that transferring knowledge from a somewhat related task can lead to negative transfer, reducing the quality of a model trained purely on the child model. It is hypothesised that the 170,000 sentences from the French parent language were not a sufficient quantity of data given the unrelatedness of French and Scottish Gaelic.

Likewise, the hierarchical transfer learning model in Section \ref{sec:4-hierarchical} also performed worse than the baseline model. Based on the literature identified in Section \ref{sec:2-transfer_learning}, it was expected that the relatedness of Irish Gaelic as an intermediary language for hierarchical transfer learning would better initialise the child Scottish Gaelic model from the initial French parent. However as shown in Figure \ref{fig:bleu_results}, the model consistently received a slightly worse \acrshort{BLEU} score than the trivial model. Worth noting is that while trivial outperformed hierarchical in terms of \acrshort{BLEU} score, a \acrshort{NIST} evaluation of the same translations contradicted these findings, implying they may be more equal than otherwise suggested.

One interesting observation from the training and validation loss diagrams of the three different models is that the validation loss of the intermediary language Irish Gaelic on hierarchical transfer learning was significantly lower after 5 epochs when compared to the entire duration of the training on the Scottish Gaelic data. The Scottish Gaelic model appears to converge at the same validation loss level during each experiment. This may suggest that the Scottish Gaelic data, comprised of a multitude of datasets, was perhaps limited in the quality of data and held back by the variety of datasets. Although this variety would improve generalisation in a high-resource dataset with a larger model, it appears to increase the difficulty in a low-resource dataset, where translations benefit from similar samples.