\chapter{Diary Sheets}
\label{AppendixC}

\subsubsection{Supervisor Meeting 1 - 28/09/2019}
This week we discussed the initial project overview that I had prepared beforehand. Dimitra gave me some alterations to clarify some minor details and provide more information sources for the context of the project.
%We also spoke about the upcoming deadlines such as the week 9 report and what will be included in it.
Dimitra suggested that for next week I should create two tables of academic references. One for papers relating to machine translation of Scottish Gaelic and the other for papers about machine translation for other low resource languages. Including the approaches and results on the tables should help identify methods that can be applied to Scottish Gaelic.


\subsubsection{Supervisor Meeting 2 - 04/10/2019}
We spoke about the reference tables I created for previous low resource machine translation research. The tables revealed that there is no published work on neural machine translation that has focuses on Scottish Gaelic. Most of the papers for low resource languages use various types of transfer learning so we decided that transfer learning should be the focus of the experiments.

Dimitra suggested that for next week I should aim to have made some progress on the introduction and plan out the structure of the dissertation (sections, headings and sub-headings). We also discussed more information sources that could be used for gathering training data such as the Scottish parliament website so I will look into these by the next meeting as well.


\subsubsection{Supervisor Meeting 3 - 11/10/2019}
We went over and made a few changes to the dissertation contents page structure I that created which includes the different sections I expect to cover in the dissertation. We also went over my dissertation introduction section and Dimitra gave a lot of helpful feedback which mainly involved adding more examples and explanations for various statements to give more context. For example, for the problem statement part I need to explain the importance of the issue and clarify what impact solving the problem could result in.

For next week I will make the changes to my introduction and ideally have made some good progress on the first draft of my literature review. 

\subsubsection{Supervisor Meeting 4 - 18/10/2019}
Over the past week I had made a start on the literature review, working on the low-resource translation approaches section. Dimitra read over it and gave me some feedback such as to add more diagrams, avoid direct quotations, and focus on explaining what the references found rather than criticising their findings. I also need to mention any figures in the text to bring the reader’s attention to them.

I also added some more information to the introduction as Dimitra recommended during our last meeting. The extra information gives more context to the project by clarifying why low-resource languages achieve poor results for neural machine translation. 

For next week we agreed that I should work on the Gaelic section of the literature review and get started on the machine translation section.

\subsubsection{Supervisor Meeting 5 - 25/10/2019}
This week I have been working on the literature review. I completed a section on data augmentation and added a section on Scottish Gaelic machine translation research. Previously I was planning to get started on the machine learning section once I had finished the Gaelic but during the week, we decided it would be better to focus on data augmentation first.

During the meeting Dimitra read over it and said it was good. She didn’t have any suggestions for changes to the work, just to keep up doing what I’ve been doing. 

We agreed that next week I will finish the sentence segmentation section and then focus on the machine translation section of the literature review. This involves writing about training data, translation techniques, and translation evaluation.
We also spoke the possibility of using a cloud platform service provider for the neural model training. This would be instead of using my own PC, which may take too long to train quite a few different models. I will look into this further in the next few weeks to see whether or not it would be worth it.

\subsubsection{Supervisor Meeting 6 - 01/11/2019}
This week I finished the sentence segmentation section from last week and started writing the machine translation section. Progress was a bit slower as I spent a lot of time reading to get a better understanding of the underlying theory behind NMT.

Dimitra suggested that I added information about using a transformer model for NMT as well as writing about translation evaluation techniques other than BLEU score (NIST and METEOR).

By the next meeting I am aiming to have completely finished the machine translation section and made a start on the machine learning section. This will likely be the most difficult section to write about in the literature review as it is very technical and there is a lot to cover.


\subsubsection{Supervisor Meeting 7 - 08/11/2019}
This week I completed the statistical machine translation section and added more technical information to the BLEU score translation evaluation section. I also started the machine learning section. This section was renamed to Deep Learning, to better reflect the content of the section. For this section so far, I have written two pages about CNNs.

Dimitra read the new content I had written for the literature review and found a few grammatical errors and places where I should add a citation to back up a statement. She also gave some very helpful feedback about what to include more information about for the remaining parts of the literature review so that I don’t spend too much time on subsections that aren’t important.

For next week I need to make the changes Dimitra recommend, finish the Deep Learning section (CNNs + RNNs), and add some more information about other methods of automatic evaluation. Once the other methods have been added, I need to compare them with the BLEU score metric.


\subsubsection{Supervisor Meeting 8 - 15/11/2019}
This week I completed the first draft of my literature review. This involved making the changes that Dimitra suggested in our last meeting and finishing the deep learning section and writing about other automatic translation evaluation methods. I also wrote the conclusion for the literature review which identifies the key points from research findings. I also arranged the 2nd marker interim meeting for 22/11/2019.

Before the meeting I emailed Dimitra the draft so she had time to go over the entire document and making notes on it to go over during our meeting. She gave me a lot of helpful feedback regarding small sections that could be improved and points that could be expanded upon further.

For next week I need to implement the changes that Dimitra suggested and create a gantt chart for the project plan that will outline the timeline schedule of each project milestone. These will be sent by Monday so she can check it again before being sent to my 2nd marker.

\subsubsection{Supervisor Meeting 9 - 22/11/2019}
This week I made some final changes to my literature review and created a project plan that provides a detailed timeline of the tasks that need to be completed next semester to ensure the project is on track. Once these were completed, I received some final feedback from Dimitra and then sent them on to my 2nd marker.

In the interim meeting with my supervisor and 2nd marker, Valerio had a lot of interesting questions about the project and gave some very useful suggestions for improvements where certain topics should be expanded further.

After all my exams are finished I will be making the recommended changes to the literature review so it is completed before returning in the new semester.

\subsubsection{Supervisor Meeting 10 - 16/01/2020}
This was the first meeting back of the final semester. Dimitra and I went over the changes that I had made to my literature review and clarified a few of the questions I had regarding the notes that we had taken in the interim meeting.

Dimitra is not available for the next supervisor meeting so we agreed upon what I should do over the next 2 weeks before we meet again. As per my project plan, I will be preparing the training data by cleaning, back-translating, and merging the data into a single training corpus. In addition, I will be using this training data to create a basic \acrshort{NMT} model to gain a better understanding of \acrshort{NMT} implementation and generate a baseline performance on which to improve upon using the low-resource \acrshort{NMT} approaches.


\subsubsection{Supervisor Meeting 11 - 30/01/2020}
My main focus over the past two weeks has been gathering more parallel training data in Scottish Gaelic and Irish. Irish is a high resource language so there is much more data available to take advantage of in comparison to Scottish Gaelic. Taking advantage of Google Translate, I translated over 100,000 lines of Irish data into Gaelic and merged it all into a large data corpus that can be used for training. I used this training data to train a basic NMT model and get a baseline performance for translation quality.

Dimitra suggested that I should implement a baseline model using a scientific paper as a guideline for the model parameters and architecture instead of the solutions from a variety of online articles. We also spoke about the possibility of analysing the Irish to Gaelic translations to filter out those that are not of high enough quality.

By our next meeting I aim to have done more research to find good baseline models for NMT and have implemented or almost ready to implement it and evaluate the translation quality. As per my project plan I will also begin covering transfer learning, starting with trivial transfer learning.

\subsubsection{Supervisor Meeting 12 - 06/02/2020}
This week I revisited some of the papers on NMT and focused on the actual implementation techniques they used. I will use this information to generate a baseline model that will be used to build upon and then compare the low resource translation techniques to.

By the time of our meeting I had been finding it quite difficult to choose a single baseline model to recreate because the ones published by the scientific papers use very complex code without the use of additional libraries such as Keras which helps to simplify some of the Tensorflow components. During our meeting Dimitra helped make the decision to focus on a articular transfer learning paper.

By our next meeting my goal is to have done more research on this specific transfer learning paper and take a lot of notes detailing the specific parameters used for training their translation models. Having this better understanding before trying to implement it straight away should help ensure that it is being done correctly.


\subsubsection{Supervisor Meeting 13 - 13/02/2020}
This week I focused on the transfer learning paper and extracted a lot of the key bits of information from both the parent and child models such as epochs, batch size, hidden state size, vocabulary size, etc. 

During the meeting with Dimitra we went over this information and she helped clarify some of the questions I had about specific details in the paper.

We decided that by our next meeting I should aim to have found out how to implement some of the key subtleties required for transfer learning. This includes details such as how to freeze word embeddings to make sure they don't update, and how to save specific layers after training. These techniques are used to take advantage of the information learned in the parent model for the child model.

\subsubsection{Supervisor Meeting 14 - 21/02/2020}
Over the past week I did some research to find out how to achieve some of the tricks used in transfer learning and also spent a lot of time working on an implementation for the baseline model.

During the meeting Dimitra and I mainly discussed the baseline model as I was running into some issues replicating the structure of the model from the transfer learning paper. This was again to the complexity of their implementation with Tensorflow. We looked at some alternative solutions, including a Tensorflow implementation based on the official Tensorflow documentation. The difficulty was implementing a sufficient sequence to sequence model with LSTM's and an Attention layer. We decided that for now it will be sufficient to implement these models with a \acrshort{GRU} instead of an LSTM.

By next week I aim to have a functional baseline model and an implementation of trivial transfer learning that expands upon this baseline model.

\subsubsection{Supervisor Meeting 15 - 27/02/2020}
This week I finally managed to implement a good baseline model for machine translation. Although I originally intended to use an \acrshort{LSTM}, I ran into some difficulty implementing the LSTM with an attention layer and creating the inference encoder and decoder models. The \acrshort{GRU} baseline model implementation is working well and will be sufficient for experimentation of transfer learning methods.

During the meeting Dimitra answered quite a few questions I had prepared about the implementation of the translation models, most importantly that I definitely need to implement a validation set during each epoch of training. We also spoke about the different parameters I could change throughout the experimentation phase to help determine the best setup for the low-resource setting.

By next week I aim to have trained a high resource language model sufficiently to carry out trivial transfer learning. If there is enough time to carry out the training, ideally I will train the Gaelic data on its own and then again separately using the high resource language model (trivial transfer learning). Afterwards I will then be able to compare the translation quality of the two models and work on the implementation section of the dissertation in parallel.


\subsubsection{Supervisor Meeting 16 - 05/03/2020}
This week I refactored my code base from a single Google Colab document into a modular python project, where components are segmented within various Python files. Along with other benefits, it means I have been able to integrate the code with a platform called Neptune AI, making it easy to track and compare training and experiments. Once the code was fully migrated, I trained a large vocabulary French dataset for 10 epochs and a small vocabulary French dataset for 10 epochs. The large one will be used to initialise a Gaelic dataset for trivial transfer learning and the small vocabulary dataset is currently being used to demonstrate the effectiveness of translation with a very small vocabulary size.

During the meeting Dimitra and I went over a few of the updates I made to the literature review and gave some suggestions for further improvements that we hadn't thought about before. She also provided some helpful input regarding some technical questions I had about the implementation.

Our next meeting will be in 2 weeks as there is a reading week. By then I hope to have completed all of my experiments with the different datasets and transfer learning approaches. Ideally I will have made a good start to the implementation section of the dissertation be on track to finish within the following weeks.


\subsubsection{Supervisor meeting 17 - 19/03/2020}
Over the past 2 weeks I have had to make a number of unexpected changes to the implementation to support transfer learning. The main feature was a vocabulary limit enforcement, ensuring that the vocabulary size of different language datasets remained the same. Subsequently, I had to reset all my training progress using the new vocabularies. I also spent a lot of time collecting new datasets as I found out that the parliamentary and technical datasets were not good for my use case. Before the meeting I sent Dimitra the latest version of my dissertation.

Regulations and government advice regarding the Coronavirus meant that this meeting and future meetings are held on Skype to avoid the spread of the virus. Dimitra had prepared a lot of feedback for the work I sent her so we went through it together during the meeting and she clarified some questions I had about the sections after the methodology.

By our next meeting I hope to have made good progress on the evaluation and results section, outlining the details of each experiment, and to have started analysis and discussion section where I will be able to draw conclusions on the results.