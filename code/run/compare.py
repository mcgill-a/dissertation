import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

def plot_loss_scores_vocab(experiments):
    epochs = range(1,21)
    x_ticks = [0,2,4,6,8,10,12,14,16,18,20]
    y_ticks = [0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25]

    for ex in experiments:
        plt.plot(epochs[:len(ex['loss'])], ex['loss'], ex['color'])

    plt.title('Baseline Vocabulary Size - Validation Loss')
    plt.ylabel('Loss')
    plt.yticks(y_ticks)
    plt.xlabel('Epoch')
    plt.xticks(x_ticks)
    plt.legend(['4000', '5000', '7000'], loc='upper right')
    plt.show()


def plot_loss_scores_length(experiments):
    epochs = range(1,21)
    x_ticks = [0,2,4,6,8,10,12,14,16,18,20]
    y_ticks = [0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25]

    for ex in experiments:
        plt.plot(epochs[:len(ex['loss'])], ex['loss'], ex['color'])

    plt.title('Baseline Sentence Length - Validation Loss')
    plt.ylabel('Loss')
    plt.yticks(y_ticks)
    plt.xlabel('Epoch')
    plt.xticks(x_ticks)
    plt.legend(['15', '20'], loc='upper right')
    plt.show()


def plot_nist_scores(experiments):
    labels = ['NIST-1', 'NIST-2', 'NIST-3', 'NIST-4', 'NIST-5']
    ind = np.arange(len(labels))
    width = 0.25 
    
    idx = 0
    for ex in experiments:
        idx += 1
        plt.bar(ind + (width * idx), ex['nist'], width, label=ex['label'], color=ex['color'])

    plt.ylabel('NIST Score')
    plt.xlabel('NIST Metric')
    plt.title('Translation NIST Scores')
    plt.xticks(ind + width*2, labels)
    plt.legend(loc='best')
    plt.show()


def plot_bleu_scores(experiments):
    labels = ['BLEU-1', 'BLEU-2', 'BLEU-3', 'BLEU-4']
    ind = np.arange(len(labels))
    width = 0.25 
    
    idx = 0
    for ex in experiments:
        idx += 1
        plt.bar(ind + (width * idx), ex['bleu'], width, label=ex['label'], color=ex['color'])

    plt.ylabel('BLEU Score')
    plt.xlabel('BLEU Metric')
    plt.title('Translation BLEU Scores')
    plt.xticks(ind + width*2, labels)
    plt.legend(loc='best')
    plt.show()

''' # 7k vocab 20 sentence length
baseline = {
    'bleu': [0.20125178496579257, 0.05802870449811433, 0.03545474454968807, 0.008854346760032756],
    'nist': [0.1695572241336696, 0.01646696917906701, 0.002661757641886449, 0.0000, 0.0000],
    'label': 'Baseline',
    'color': '#C70039'
}

trivial = {
    'bleu': [0.1695572241336696, 0.01646696917906701, 0.002661757641886449, 0.0000],
    'nist': [0.1695572241336696, 0.01646696917906701, 0.002661757641886449, 0.0000, 0.0000],
    'label': 'Trivial',
    'color': '#900C3F'
}

hierarchical = {
    'bleu': [0.1695572241336696, 0.01646696917906701, 0.002661757641886449, 0.0000],
    'nist': [0.1695572241336696, 0.01646696917906701, 0.002661757641886449, 0.0000, 0.0000],
    'label': 'Hierarchical',
    'color': '#581845'
}
'''

# 5k vocab 15 sentence length
baseline = {
    'bleu': [0.250678778959121, 0.07753062460044147, 0.04692392227696155, 0.015734797729868074],
    'nist': [1.1310974667539422, 1.1871084289207503, 1.1945346292246233, 1.197275808535083, 1.197709499835481],
    'label': 'Baseline',
    'color': '#C70039'
}

trivial = {
    'bleu': [0.1789966348199435, 0.019664358396084866, 0.0033590555729730324, 0.00042204140810281647],
    'nist': [0.7616245450765736, 0.7698261562666058, 0.7698772213083672, 0.7698772213083672, 0.7698772213083672],
    'label': 'Trivial',
    'color': '#900C3F'
}

hierarchical = {
    'bleu': [0.1723352619339628, 0.013307074087376991, 0.0000, 0.0000],
    'nist': [0.7771002066399245, 0.7814735192392778, 0.7814735192392778, 0.7814735192392778, 0.7814735192392778],
    'label': 'Hierarchical',
    'color': '#581845'
}

#######################################################

vocab4k = {
    'loss': [1.7660052358116234, 1.467781496640727, 1.148745621765516,0.9290629078670102,
    0.8275403423203948, 0.7438556449847985, 0.7318846212072267, 0.7111133995635733,
    0.7113203380812597, 0.68858076261552, 0.6705967933762798, 0.6827919760626324,
    0.6505094673587473, 0.6738043677740992, 0.6991398403657734, 0.6832141742027925,
    0.6503916842996745, 0.7088757213308008, 0.7651974666678445, 0.7651974666678445],
    'bleu': [0.1456005981353993, 0.03952732354389121, 0.019308746830021966, 0.003564009885329991],
    #'nist': [1.1310974667539422, 1.1871084289207503, 1.1945346292246233, 1.197275808535083, 1.197709499835481],
    'label': '4000',
    'color': '#355C7D',
    
}

vocab5k = {
    'loss': [1.6856876430590508, 1.3843647287695446, 1.1092307116445257, 0.8146348814608643, 0.6044633312778578, 0.5052758732717999, 0.4453104509668456, 0.4058896180509862, 0.3904163138889476, 0.38768540244570093, 0.3605657578420244, 0.359518651927703, 0.3587702255881294, 0.363081622601214, 0.3780823710955968, 0.4038148188541607, 0.3775816467997119, 0.3814210441807357, 0.38819231237851, 0.3908128384918394],
    'bleu': [0.250678778959121, 0.07753062460044147, 0.04692392227696155, 0.015734797729868074],
    #'nist': [1.1310974667539422, 1.1871084289207503, 1.1945346292246233, 1.197275808535083, 1.197709499835481],
    'label': '5000',
    'color': '#6C5B7B',
}

vocab7k = {
    'loss': [1.7070083038582986, 1.3661732525456676, 1.0724885641540611, 0.7679230648180397, 0.599556667452359, 0.5046975390357866, 0.4522073805661491, 0.414901299453572, 0.3953007290870445, 0.4229970186619469, 0.37754170633646666, 0.3771711563619461, 0.3744923783600001, 0.3790544275173825, 0.38463621681237087, 0.38869207537635253, 0.39306217164459806, 0.4186655496200804, 0.41912351234123, 0.4283970830347830],
    'bleu': [0.20125178496579257, 0.05802870449811433, 0.03545474454968807, 0.008854346760032756],
    #'nist': [1.1310974667539422, 1.1871084289207503, 1.1945346292246233, 1.197275808535083, 1.197709499835481],
    'label': '7000',
    'color': '#C06C84',
}


fifteen5k = {
    'loss': [2.122611349185537, 1.6440178554408489, 1.2034010859662587, 0.8833192076738011, 0.700732002856065, 0.5926846524308669, 0.5628048379929678, 0.4929668589868188, 0.47448760855094846, 0.4573862564666814, 0.4590558058418527, 0.45865780570321535, 0.4645605423093186, 0.46353063202041717, 0.4773456608871218, 0.47193401768502996, 0.48582368745583965, 0.5038909380477169, 0.5011794442573954, 0.5100559665249816],
    'bleu': [0.250678778959121, 0.07753062460044147, 0.04692392227696155, 0.015734797729868074],
    'nist': [1.1310974667539422, 1.1871084289207503, 1.1945346292246233, 1.197275808535083, 1.197709499835481],
    'label': '15',
    'color': '#355C7D'
}

twenty5k = {
    'loss': [1.6611280039339313, 1.316778191571964, 0.9665533395253272, 0.6846300241583019, 0.5391411123426916, 0.4589007249483114, 0.42235283137054885, 0.3807469567750991, 0.3800450491716264, 0.35928622652543035, 0.3553636663671186, 0.3546219919875307, 0.35415710057923705, 0.3627715429844018, 0.36836040488065835, 0.3684358488156404, 0.37864118646991357, 0.38364733897299863, 0.39302319099305344, 0.4054735297342542],
    'bleu': [0.20996800293476267, 0.06478095645156824, 0.03831207169717042, 0.00917676111034701],
    'nist': [0.958777549015901, 1.00807822306991, 1.012679760060041, 1.0135484368914756, 1.0136432349192661],
    'label': '20',
    'color': '#6C5B7B',
}

vocab = []
vocab.append(vocab4k)
vocab.append(vocab5k)
vocab.append(vocab7k)

sentence = []
sentence.append(fifteen5k)
sentence.append(twenty5k)

plot_loss_scores_vocab(vocab)
plot_bleu_scores(vocab)
plot_loss_scores_length(sentence)
plot_bleu_scores(sentence)
#######################################################


experiments = []
experiments.append(baseline)
experiments.append(trivial)
experiments.append(hierarchical)

plot_bleu_scores(experiments)
plot_nist_scores(experiments)